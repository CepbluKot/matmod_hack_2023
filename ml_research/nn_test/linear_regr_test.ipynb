{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = pd.read_csv('/home/oleg/Documents/matmod_challeng/X.csv')\n",
    "y_df = pd.read_csv('/home/oleg/Documents/matmod_challeng/y.csv')\n",
    "\n",
    "\n",
    "x_vals = x_df.columns\n",
    "predicted_cols = y_df.columns\n",
    "\n",
    "\n",
    "merged_df = pd.merge(x_df, y_df, on=[\"engine_id\", \"flight_datetime\", \"flight_phase\"])\n",
    "\n",
    "merged_df = merged_df.dropna(axis=1, how='all')\n",
    "\n",
    "merged_df = merged_df.drop(x_vals.intersection(predicted_cols) , axis=1)\n",
    "merged_df = merged_df.dropna(axis=1, how='all')\n",
    "merged_df = merged_df.fillna(0)\n",
    "merged_df = merged_df.loc[:,merged_df.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "\n",
    "to_rm = [  'aircraft_id',  'engine_position', 'number_blades', 'engine_family', 'engine_type', 'manufacturer', 'aircraft_family', 'aircraft_grp', 'ac_manufacturer', 'aircraft_type', ]\n",
    "merged_df = merged_df.drop(to_rm, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = x_vals.drop(to_rm).drop(['engine_id', 'flight_datetime', 'flight_phase'])\n",
    "predicted_cols = predicted_cols.drop(['engine_id', 'flight_datetime', 'flight_phase'])\n",
    "\n",
    "\n",
    "x_vals = x_vals.intersection(merged_df.columns)\n",
    "predicted_cols = predicted_cols.intersection(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = merged_df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = merged_df.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_features = train_dataset[x_vals]\n",
    "test_features = test_dataset[x_vals]\n",
    "\n",
    "train_labels = train_dataset['ZTLA_D']\n",
    "test_labels = test_dataset['ZTLA_D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "normalizer.adapt(train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = np.array(train_features)\n",
    "\n",
    "train_normalizer = layers.Normalization()\n",
    "train_normalizer.adapt(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = tf.keras.Sequential([\n",
    "    train_normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=1000,\n",
    "    # Suppress logging.\n",
    "    verbose=0,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)\n",
    "\n",
    "\n",
    "pred = train_model.predict(test_features)\n",
    "\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.028]\n",
      " [ 0.199]\n",
      " [ 0.107]\n",
      " ...\n",
      " [-0.155]\n",
      " [ 0.228]\n",
      " [-0.234]]\n",
      "-313.980651191634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "print(pred)\n",
    "print(r2_score(test_labels , pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-313"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
